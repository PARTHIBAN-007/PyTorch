{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PARTHIBAN-007/PyTorch/blob/main/PyTorch_Dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5wwl4hI9fSC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.data import Dataset, DataLoader\n",
        "from torch.utils.datasets import ImageFolder\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aljBW_Bs-TI4"
      },
      "outputs": [],
      "source": [
        "class DogsVsCats(Dataset):\n",
        "  def __init__(self,path_to_folder):\n",
        "    path_to_dogs = os.path.join(path_to_folder,\"dogs\")\n",
        "    path_to_cats = os.path.join(path_to_folder,\"cats\")\n",
        "\n",
        "    dog_files = os.listdir(path_to_dogs)\n",
        "    cat_files = os.listdir(path_to_cats)\n",
        "\n",
        "    path_to_dog_files = [os.path.join(path_to_dogs,file) for file in dog_files]\n",
        "    path_to_cat_files = [os.path.join(path_to_cats,file) for file in cat_files]\n",
        "\n",
        "    self.training_files = path_to_dog_files + path_to_cat_files\n",
        "    self.dog_label , self.cat_label = 0,1\n",
        "\n",
        "    self.transform = transforms.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.training_files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    path_to_image = self.training_files[idx]\n",
        "\n",
        "    if \"Dog\" in path_to_image:\n",
        "      label = self.dog_label\n",
        "    else:\n",
        "      label = self.cat_label\n",
        "  image = Image.open(path_to_image)\n",
        "  image = self.transform(image)\n",
        "\n",
        "  return image,label\n",
        "\n",
        "dogvscat = DogsVsCats(\"../../data/dogsvscats/\")\n",
        "\n",
        "print(f\"Total Training samples: {len(dogvscat)}\")\n",
        "\n",
        "for image, labels in dogvscat:\n",
        "  print(f\"Image Label: {labels}\")\n",
        "  print(f\"Image Shape: {image.shape}\")\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9fxqwpd_73F"
      },
      "source": [
        "### Built In PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wQo-aEs_7Lq"
      },
      "outputs": [],
      "source": [
        "dogsvscatsloader = DataLoader(\n",
        "    dogvscat,\n",
        "    batch_size = 16,\n",
        "    shuffle = False\n",
        ")\n",
        "\n",
        "for image,labels in dogsvscatsloader:\n",
        "  print(f\"Image label: {label}\")\n",
        "  print(f\"Image Shape: {image.shape}\")\n",
        "  break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhUnpP8dBKzP"
      },
      "outputs": [],
      "source": [
        "\n",
        "img_transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "    ]\n",
        ")\n",
        "\n",
        "class DogsVsCats(Dataset):\n",
        "  def __init__(self,path_to_folder):\n",
        "    path_to_dogs = os.path.join(path_to_folder,\"dogs\")\n",
        "    path_to_cats = os.path.join(path_to_folder,\"cats\")\n",
        "\n",
        "    dog_files = os.listdir(path_to_dogs)\n",
        "    cat_files = os.listdir(path_to_cats)\n",
        "\n",
        "    path_to_dog_files = [os.path.join(path_to_dogs,file) for file in dog_files]\n",
        "    path_to_cat_files = [os.path.join(path_to_cats,file) for file in cat_files]\n",
        "\n",
        "    self.training_files = path_to_dog_files + path_to_cat_files\n",
        "    self.dog_label , self.cat_label = 0,1\n",
        "\n",
        "    self.transform = transforms.ToTensor()\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.training_files)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    path_to_image = self.training_files[idx]\n",
        "\n",
        "    if \"Dog\" in path_to_image:\n",
        "      label = self.dog_label\n",
        "    else:\n",
        "      label = self.cat_label\n",
        "    image = Image.open(path_to_image)\n",
        "    image = self.transform(image)\n",
        "\n",
        "    return image,label\n",
        "\n",
        "dogvscat = DogsVsCats(\"../../data/dogsvscats/\")\n",
        "\n",
        "dogsvscatsloader = DataLoader(dogvscat,\n",
        "                             batch_size=16,\n",
        "                             shuffle=True)\n",
        "\n",
        "for images, labels in dogsvscatsloader:\n",
        "    print(images.shape)\n",
        "    print(labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_samples = int(0.9 * len(dogvscat))\n",
        "test_samples = len(dogvscat) - train_samples\n",
        "\n",
        "print(f\"Number of Training Samples: {train_samples} \")\n",
        "print(f\"Number of Test Samples: {test_samples} \")\n",
        "\n",
        "\n",
        "train_dataset ,  test_dataset = torch.utils.data.random_split(dogvscat, lengths=  [train_samples,test_samples])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size = 16,\n",
        "                          shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size = 16,\n",
        "                         shuffle = False)\n",
        "\n",
        "for images , labels in train_loader:\n",
        "    print(images.shape)\n",
        "    print(labels)\n",
        "    break\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    print(images.shape)\n",
        "    print(labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Built in DataLoader\n",
        "dogvscat = ImageFolder(root = \"./dogvscat\",\n",
        "                       transform = img_transforms)\n",
        "\n",
        "print(dogvscat.classes)\n",
        "\n",
        "train_dataset , test_dataset = torch.utils.data.random_split(dogvscat,lengths=  [train_samples,test_samples])\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size = 16,\n",
        "                          shuffle = True)\n",
        "\n",
        "test_loader = DataLoader(test_loader,\n",
        "                         batch_size = 16,\n",
        "                         shuffle = False)\n",
        "\n",
        "for images,labels in train_loader:\n",
        "    print(images.shape)\n",
        "    print(labels)\n",
        "    break\n",
        "\n",
        "for images,labels in test_loader:\n",
        "    print(images.shape)\n",
        "    print(labels)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = \"/aclImdb/train\"\n",
        "\n",
        "path_to_pos_fld = os.path.join(path_to_data, \"pos\")\n",
        "path_to_neg_fld = os.path.join(path_to_data, \"neg\")\n",
        "\n",
        "path_to_pos_txt = [os.path.join(path_to_pos_fld, file) for file in os.listdir(path_to_pos_fld)]\n",
        "path_to_neg_txt = [os.path.join(path_to_neg_fld, file) for file in os.listdir(path_to_neg_fld)]\n",
        "\n",
        "training_files = path_to_pos_txt + path_to_neg_txt\n",
        "\n",
        "alltxt = \"\"\n",
        "for file in tqdm(training_files):\n",
        "    with open(file, \"r\") as f:\n",
        "        text = f.readlines()\n",
        "        alltxt += text[0]\n",
        "\n",
        "unique_counts = dict(Counter(alltxt))\n",
        "characters = sorted([key for (key,value) in unique_counts.items() if value > 1500])\n",
        "\n",
        "characters.append(\"<UNK>\")\n",
        "\n",
        "characters.append(\"<PAD>\")\n",
        "\n",
        "char2idx = {c:i for i,c in enumerate(characters)}\n",
        "idx2char = {i:c for i,c in enumerate(characters)}\n",
        "\n",
        "print(char2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, path_to_data, char2idx): \n",
        "        path_to_pos_fld = os.path.join(path_to_data, \"pos\")\n",
        "        path_to_neg_fld = os.path.join(path_to_data, \"neg\")\n",
        "        \n",
        "        path_to_pos_txt = [os.path.join(path_to_pos_fld, file) for file in os.listdir(path_to_pos_fld)]\n",
        "        path_to_neg_txt = [os.path.join(path_to_neg_fld, file) for file in os.listdir(path_to_neg_fld)]\n",
        "        \n",
        "        self.training_files = path_to_pos_txt + path_to_neg_txt\n",
        "        self.tokenizer = char2idx\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.training_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        path_to_txt = self.training_files[idx]\n",
        "        \n",
        "        with open(path_to_txt, \"r\") as f:\n",
        "            txt = f.readlines()[0]\n",
        "            \n",
        "        tokenized = []\n",
        "        for char in txt:\n",
        "            if char in self.tokenizer.keys(): \n",
        "                tokenized.append(self.tokenizer[char])\n",
        "            else:\n",
        "                tokenized.append(self.tokenizer[\"<UNK>\"]) \n",
        "                \n",
        "                \n",
        "        sample = torch.tensor(tokenized) \n",
        "        if \"neg\" in path_to_txt:\n",
        "            label = 0\n",
        "        else:\n",
        "            label = 1\n",
        "        \n",
        "        return sample, label\n",
        "        \n",
        "        \n",
        "    \n",
        "imdbdataset = IMDBDataset(\"/aclImdb/train\", char2idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Pad sequence\n",
        "\n",
        "a = torch.ones(10)\n",
        "b = torch.ones(8)\n",
        "c = torch.ones(2)\n",
        "padded = nn.utils.rnn.pad_sequence([a, b, c], batch_first=True, padding_value=999) \n",
        "\n",
        "print(padded)\n",
        "print(padded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_collator(batch):\n",
        "    texts, labels = [], []\n",
        "    \n",
        "    for text, label in batch:\n",
        "        labels.append(label)\n",
        "        texts.append(text)\n",
        "        \n",
        "    labels = torch.tensor(labels)\n",
        "    \n",
        "    texts = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=char2idx[\"<PAD>\"])\n",
        "    return texts, labels    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Without Data Collator\n",
        "imdbloader = DataLoader(imdbdataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
        "\n",
        "for text, label in imdbloader:\n",
        "    print(text.shape)\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyML1A67kykY++4MVjz9ioab",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
